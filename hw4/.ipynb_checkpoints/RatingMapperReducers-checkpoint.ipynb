{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPSC6770- Assignment4\n",
    "## Author: Wenkang Wei\n",
    "## This is the jupyter notebook used to create the map, reduce functions and bash command files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Currently Loaded Modules:\n",
      "  1) anaconda3/5.1.0-gcc/8.3.1         3) hadoop/3.2.1-gcc/8.3.1\n",
      "  2) openjdk/1.8.0_222-b10-gcc/8.3.1\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!module list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: find mean, median and standard deviation of ratings of each genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapper and Reducer for computing Mean values of rating of each genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mycodes/meanRatingMapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mycodes/meanRatingMapper.py\n",
    "#!/usr/bin/python3\n",
    "\n",
    "#mapper\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "# read movies file\n",
    "movieFile = \"./movies.csv\"\n",
    "movieList = {}\n",
    "\n",
    "with open(movieFile, mode = 'r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    for row in reader:\n",
    "        movieId = row[0]\n",
    "        movieList[movieId] = {}\n",
    "        movieList[movieId][\"title\"] = row[1]\n",
    "        movieList[movieId][\"genre\"] = row[2]\n",
    "\n",
    "\n",
    "for oneMovie in sys.stdin:\n",
    "    oneMovie= oneMovie.strip()\n",
    "    ratingInfo = oneMovie.split(\",\")\n",
    "    try:\n",
    "        userId = ratingInfo[0]\n",
    "        movieId = ratingInfo[1]\n",
    "        rating = float(ratingInfo[2])\n",
    "        movieTitle = movieList[movieId][\"title\"]\n",
    "        movieGenre = movieList[movieId][\"genre\"]\n",
    "        # Split the complex genres into a list of different genres\n",
    "        # then find the ratings of each genre \n",
    "        genres = movieGenre.split(\"|\")\n",
    "        for genre in genres:\n",
    "            # print the genre-rating pairs\n",
    "            print(\"%s\\t%s\"%(genre,rating))\n",
    "        pass\n",
    "    \n",
    "    except  IndexError:\n",
    "        continue\n",
    "    except  ValueError:\n",
    "        continue\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: movielens/rating.csv: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!cat  movielens/rating.csv | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieId,title,genres\n",
      "1,Toy Story (1995),Adventure|Animation|Children|Comedy|Fantasy\n",
      "2,Jumanji (1995),Adventure|Children|Fantasy\n",
      "3,Grumpier Old Men (1995),Comedy|Romance\n",
      "4,Waiting to Exhale (1995),Comedy|Drama|Romance\n",
      "5,Father of the Bride Part II (1995),Comedy\n",
      "6,Heat (1995),Action|Crime|Thriller\n",
      "7,Sabrina (1995),Comedy|Romance\n",
      "8,Tom and Huck (1995),Adventure|Children\n",
      "9,Sudden Death (1995),Action\n",
      "cat: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!cat  movielens/movies.csv | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mycodes/meanRatingReducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mycodes/meanRatingReducer.py\n",
    "#!/usr/bin/python3\n",
    "\n",
    "#Note that before using reducer, we need to sort/shuffle data\n",
    "import sys \n",
    "\n",
    "movie_genre = None\n",
    "rating_ls = []\n",
    "for line in sys.stdin:\n",
    "    line = line.strip()\n",
    "    genre, rating = line.split(\"\\t\", 2)\n",
    "\n",
    "    try:\n",
    "        if  len(rating_ls)>0 and  movie_genre != genre:\n",
    "            # Find the mean of rating of a genre \n",
    "            \n",
    "            genre_mean = sum(rating_ls)/float(len(rating_ls))\n",
    "            print(\"%s\\t%f\" % ( movie_genre, genre_mean))\n",
    "            rating_ls.clear()\n",
    "        rating = float(rating)\n",
    "        rating_ls.append(rating)    \n",
    "        movie_genre = genre\n",
    "    except ValueError: \n",
    "        continue\n",
    "\n",
    "#Check the last genre in list and print its median\n",
    "if  len(rating_ls)>0:\n",
    "    genre_mean = sum(rating_ls)/float(len(rating_ls))\n",
    "    print(\"%s\\t%f\" % ( movie_genre, genre_mean))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapper Reducer for Median Rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mycodes/medianRatingMapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mycodes/medianRatingMapper.py\n",
    "#!/usr/bin/python3\n",
    "\n",
    "#mapper\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "# read movies file\n",
    "movieFile = \"./movies.csv\"\n",
    "movieList = {}\n",
    "\n",
    "with open(movieFile, mode = 'r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    for row in reader:\n",
    "        movieId = row[0]\n",
    "        movieList[movieId] = {}\n",
    "        movieList[movieId][\"title\"] = row[1]\n",
    "        movieList[movieId][\"genre\"] = row[2]\n",
    "\n",
    "\n",
    "for oneMovie in sys.stdin:\n",
    "    oneMovie= oneMovie.strip()\n",
    "    ratingInfo = oneMovie.split(\",\")\n",
    "    try:\n",
    "        userId = ratingInfo[0]\n",
    "        movieId = ratingInfo[1]\n",
    "        rating = float(ratingInfo[2])\n",
    "        movieTitle = movieList[movieId][\"title\"]\n",
    "        movieGenre = movieList[movieId][\"genre\"]\n",
    "        # Split the complex genres into a list of different genres\n",
    "        # then find the ratings of each genre \n",
    "        genres = movieGenre.split(\"|\")\n",
    "        for genre in genres:\n",
    "            # print the genre-rating pairs\n",
    "            print(\"%s\\t%s\"%(genre,rating))\n",
    "        pass\n",
    "    \n",
    "    except  IndexError:\n",
    "        continue\n",
    "    except  ValueError:\n",
    "        continue\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mycodes/medianRatingReducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mycodes/medianRatingReducer.py\n",
    "#!/usr/bin/python3\n",
    "\n",
    "#Note that before using reducer, we need to sort/shuffle data\n",
    "import sys \n",
    "\n",
    "movie_genre = None\n",
    "rating_ls = []\n",
    "for line in sys.stdin:\n",
    "    line = line.strip()\n",
    "    genre, rating = line.split(\"\\t\", 2)\n",
    "\n",
    "    try:\n",
    "        if  len(rating_ls)>0 and  movie_genre != genre:\n",
    "            # Find the median of rating of a genre by sorting and finding the middel value of list\n",
    "            # Note: sort must be applied in hdfs before using medianRatingReducer, so that\n",
    "            # value in the middle position = median\n",
    "            index = len(rating_ls)//2\n",
    "            genre_median = rating_ls[index]\n",
    "            print(\"%s\\t%f\" % ( movie_genre, genre_median))\n",
    "            rating_ls.clear()\n",
    "        rating = float(rating)\n",
    "        rating_ls.append(rating)    \n",
    "        movie_genre = genre\n",
    "    except ValueError: \n",
    "        continue\n",
    "\n",
    "#Check the last genre in list and print its median\n",
    "if  len(rating_ls)>0:\n",
    "    index = len(rating_ls)//2\n",
    "    genre_median = rating_ls[index]\n",
    "    print(\"%s\\t%f\" % ( movie_genre, genre_median))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapper Reducer Standard Deviation Rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mycodes/stdRatingMapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mycodes/stdRatingMapper.py\n",
    "#!/usr/bin/python3\n",
    "\n",
    "#mapper\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "# read movies file\n",
    "movieFile = \"./movies.csv\"\n",
    "movieList = {}\n",
    "\n",
    "with open(movieFile, mode = 'r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    for row in reader:\n",
    "        movieId = row[0]\n",
    "        movieList[movieId] = {}\n",
    "        movieList[movieId][\"title\"] = row[1]\n",
    "        movieList[movieId][\"genre\"] = row[2]\n",
    "\n",
    "\n",
    "for oneMovie in sys.stdin:\n",
    "    oneMovie= oneMovie.strip()\n",
    "    ratingInfo = oneMovie.split(\",\")\n",
    "    try:\n",
    "        userId = ratingInfo[0]\n",
    "        movieId = ratingInfo[1]\n",
    "        rating = float(ratingInfo[2])\n",
    "        movieTitle = movieList[movieId][\"title\"]\n",
    "        movieGenre = movieList[movieId][\"genre\"]\n",
    "        # Split the complex genres into a list of different genres\n",
    "        # then find the ratings of each genre \n",
    "        genres = movieGenre.split(\"|\")\n",
    "        for genre in genres:\n",
    "            # print the genre-rating pairs\n",
    "            print(\"%s\\t%s\"%(genre,rating))\n",
    "        pass\n",
    "    \n",
    "    except  IndexError:\n",
    "        continue\n",
    "    except  ValueError:\n",
    "        continue\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mycodes/stdRatingReducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mycodes/stdRatingReducer.py\n",
    "#!/usr/bin/python3\n",
    "\n",
    "import sys \n",
    "import math\n",
    "movie_genre = None\n",
    "rating_ls = []\n",
    "for line in sys.stdin:\n",
    "    line = line.strip()\n",
    "    genre, rating = line.split(\"\\t\", 2)\n",
    "\n",
    "    try:\n",
    "        if  len(rating_ls)>0 and  movie_genre != genre:\n",
    "            # Find standard derivate of rating list of one genre\n",
    "            mean_val = sum(rating_ls)/len(rating_ls)\n",
    "            val_ls = [(val - mean_val)**2 for val in rating_ls]\n",
    "            std = math.sqrt(sum(val_ls)/len(val_ls))\n",
    "            print(\"%s\\t%f\" % ( movie_genre, std))\n",
    "            # reset the list of ratings of current genre\n",
    "            rating_ls.clear()\n",
    "        rating = float(rating)\n",
    "        rating_ls.append(rating)    \n",
    "        movie_genre = genre\n",
    "    except ValueError: \n",
    "        continue\n",
    "\n",
    "#Check the last genre in list and print its standard devirative\n",
    "if  len(rating_ls)>0:\n",
    "    mean_val = sum(rating_ls)/len(rating_ls)\n",
    "    val_ls = [(val - mean_val)**2 for val in rating_ls]\n",
    "    std = math.sqrt(sum(val_ls)/len(val_ls))\n",
    "    print(\"%s\\t%f\" % ( movie_genre, std))\n",
    "    rating_ls.clear()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Identify which user provides the most rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mycodes/userRatingMapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mycodes/userRatingMapper.py\n",
    "#!/usr/bin/python3\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "# read movies file\n",
    "movieFile = \"./movies.csv\"\n",
    "movieList = {}\n",
    "\n",
    "with open(movieFile, mode = 'r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    for row in reader:\n",
    "        movieId = row[0]\n",
    "        movieList[movieId] = {}\n",
    "        movieList[movieId][\"title\"] = row[1]\n",
    "        movieList[movieId][\"genre\"] = row[2]\n",
    "\n",
    "user_count = {}\n",
    "for oneMovie in sys.stdin:\n",
    "    oneMovie= oneMovie.strip()\n",
    "    ratingInfo = oneMovie.split(\",\")\n",
    "    try:\n",
    "        #parse the userId, movieId, title, genres from dataset\n",
    "        userId = ratingInfo[0]\n",
    "        movieId = ratingInfo[1]\n",
    "        movieTitle = movieList[movieId][\"title\"]\n",
    "        movieGenre = movieList[movieId][\"genre\"]\n",
    "        # Split  genres into different genre\n",
    "        # and Find each userID-movieGenre pair and the counts that this user watch this genre of movie\n",
    "        genres = movieGenre.split(\"|\")\n",
    "        rating = float(ratingInfo[2])\n",
    "        for genre in genres:\n",
    "            key =userId + '|'+ genre\n",
    "            # store the count of user-movieGenre into dictionary\n",
    "            if key not in user_count.keys():\n",
    "                user_count[key] =0\n",
    "            user_count[key] += 1\n",
    "            \n",
    "    except  IndexError:\n",
    "        continue\n",
    "    except  ValueError:\n",
    "        continue\n",
    "        pass\n",
    "    \n",
    "for Id in user_count.keys():\n",
    "    # Need to put User Id first, Since I want to sort by user Id to\n",
    "    # find all information of one user first in reducer\n",
    "    userId, genre = Id.split(\"|\")\n",
    "    print(\"%s\\t%s\\t%d\"%(userId, genre, user_count[Id]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mycodes/userRatingReducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mycodes/userRatingReducer.py\n",
    "#!/usr/bin/python3\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "#userId that we check previously\n",
    "prev_userId = None\n",
    "# Total rating counts of current user \n",
    "cumulative_count = 0\n",
    "# user id of the user who provides the most ratings\n",
    "max_userId = None\n",
    "# Rating Count from the user who provides the most ratings\n",
    "max_count = 0\n",
    "\n",
    "#The genre name that the user providing most rating watches most\n",
    "most_genre =None\n",
    "#Count of the genre that the user providing most rating watches most\n",
    "most_genre_count = 0\n",
    "\n",
    "#Count of the genre that current user watches most\n",
    "current_genre_count = 0\n",
    "# the genre name that current user watches most\n",
    "current_genre = None\n",
    "\n",
    "\n",
    "for line in sys.stdin:\n",
    "    userId, genre,genre_count = line.split(\"\\t\")\n",
    "    genre_count = float(genre_count)\n",
    "    # Find the genre that current user watches most\n",
    "    if prev_userId== None or (prev_userId == userId and genre_count >current_genre_count):\n",
    "        #if previous userId = None, just initialize current_genre_count\n",
    "        # if previous userId == user Id,update the genre with maximum count of this user\n",
    "        current_genre_count = genre_count\n",
    "        current_genre = genre\n",
    "        \n",
    "    # Find the user that provides most rating\n",
    "    if prev_userId and prev_userId != userId:\n",
    "        # update user that provides most ratings\n",
    "        if max_count < cumulative_count:\n",
    "            max_count = cumulative_count\n",
    "            max_userId = prev_userId\n",
    "            most_genre = current_genre\n",
    "            most_genre_count = current_genre_count\n",
    "        # reset cumulative count of this user \n",
    "        # and start compute total count of the next user\n",
    "        cumulative_count = 0\n",
    "    #Update total count of rating of current user and userId\n",
    "    cumulative_count += genre_count\n",
    "    prev_userId = userId \n",
    "    \n",
    "# check the last user information\n",
    "if prev_userId and prev_userId != userId:\n",
    "        # update user that provides most ratings\n",
    "        if max_count < cumulative_count:\n",
    "            max_count = cumulative_count\n",
    "            max_userId = prev_userId\n",
    "            most_genre = current_genre\n",
    "            most_genre_count = current_genre_count\n",
    "        cumulative_count = 0\n",
    "    \n",
    "print(\"User Identification:\\n %s -- Total Rating Counts: %d -- Most Rated Genre:%s - %d\"%(max_userId,max_count,most_genre, most_genre_count))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bash files to test and run the whole program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the program for hw4 using hdfs dfs -cat method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run_test_mapreduce.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile run_test_mapreduce.sh\n",
    "\n",
    "module add openjdk/1.8.0_222-b10-gcc/8.3.1\n",
    "module add hadoop/3.2.1-gcc/8.3.1\n",
    "\n",
    "# copy configurations to home directory\n",
    "cp -rf ./hadoop_palmetto /home/$USER/\n",
    "\n",
    "./init_hadoop.sh\n",
    "\n",
    "echo \"Copying movielens data to current directory..\"\n",
    "cp -rf /zfs/citi/movielens .\n",
    "\n",
    "# Note All mapper functions read movies.csv in ./movies.csv directory for testing\n",
    "# If using hdfs dfs -cat ....| mapper.py ... to test map reduce, need to do this step \n",
    "# if using mapred streaming, we don't need to copy movies.csv to local directory \n",
    "cp ./movielens/movies.csv ./ \n",
    "\n",
    "echo \"Data download Completed\"\n",
    "\n",
    "export HADOOP_CONF_DIR=\"/home/${USER}/hadoop_palmetto/config/\"\n",
    "\n",
    "# create data folder and move data to hdfs\n",
    "hdfs  dfs -mkdir /user\n",
    "hdfs  dfs -mkdir /user/$USER/\n",
    "hdfs  dfs -mkdir /user/$USER/data\n",
    "hdfs  dfs -put ./movielens data/\n",
    "hdfs  dfs -ls data/movielens/\n",
    "\n",
    "echo \"\"\n",
    "echo \"-------------------------------------\"\n",
    "echo \"Starting MappReducer Program for HW4\"\n",
    "echo \"-------------------------------------\"\n",
    "\n",
    "# Question 1\n",
    "#Compute mean, median, std of ratings of each genre\n",
    "echo \"Computing Means of ratings of each genre:\"\n",
    "hdfs dfs -cat data/movielens/ratings.csv 2>/dev/null \\\n",
    "        | python mycodes/meanRatingMapper.py \\\n",
    "        |sort | python mycodes/meanRatingReducer.py > rating_mean_testoutput.txt\n",
    "\n",
    "echo \"Mean of ratings of each genre:\"\n",
    "cat rating_mean_testoutput.txt\n",
    "\n",
    "echo \"Computing Medians of ratings of each genre:\"\n",
    "hdfs  dfs -cat data/movielens/ratings.csv 2>/dev/null \\\n",
    "        | python mycodes/medianRatingMapper.py \\\n",
    "        |sort | python mycodes/medianRatingReducer.py > rating_median_testoutput.txt\n",
    "\n",
    "echo \"Median of ratings of each genre:\"\n",
    "cat rating_median_testoutput.txt\n",
    "\n",
    "echo \"Computing Standard Deviation of ratings of each genre:\"\n",
    "hdfs  dfs -cat data/movielens/ratings.csv 2>/dev/null \\\n",
    "        | python mycodes/stdRatingMapper.py \\\n",
    "        |sort | python mycodes/stdRatingReducer.py > rating_std_testoutput.txt\n",
    "\n",
    "echo \"Standard Deviation of ratings of each genre:\"\n",
    "cat rating_std_testoutput.txt\n",
    "\n",
    "# Question 2\n",
    "# Find the user who provides most ratings and the genre this user watch most\n",
    "echo \"Find the user who provides most ratings and the genre this user watch most:\"\n",
    "hdfs dfs -cat data/movielens/ratings.csv 2>/dev/null \\\n",
    "        | python mycodes/userRatingMapper.py \\\n",
    "        |sort|python mycodes/userRatingReducer.py > user_ratings_testoutput.txt\n",
    "\n",
    "cat user_ratings_testoutput.txt\n",
    "./stop_hadoop.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Reduce Commands using mapred streaming for HW4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run_all.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile run_all.sh\n",
    "\n",
    "module add openjdk/1.8.0_222-b10-gcc/8.3.1\n",
    "module add hadoop/3.2.1-gcc/8.3.1\n",
    "\n",
    "echo \"Hadoop config file to home directory\"\n",
    "cp -rf ./hadoop_palmetto /home/$USER/\n",
    "\n",
    "sleep 2\n",
    "\n",
    "./init_hadoop.sh\n",
    "\n",
    "\n",
    "echo \"Copying movielens data to current directory and HDFS ...\"\n",
    "cp -rf /zfs/citi/movielens .\n",
    "\n",
    "\n",
    "export HADOOP_CONF_DIR=\"/home/${USER}/hadoop_palmetto/config/\"\n",
    "\n",
    "# # create data folder and move data to hdfs\n",
    "hdfs  dfs -mkdir /user\n",
    "hdfs  dfs -mkdir /user/$USER/\n",
    "hdfs  dfs -mkdir /user/$USER/data\n",
    "hdfs  dfs -put ./movielens data/\n",
    "hdfs  dfs -ls data/movielens/\n",
    "\n",
    "echo \"Data download Completed\"\n",
    "\n",
    "sleep 3\n",
    "\n",
    "\n",
    "hdfs dfs -rm -r data/ratings_mean/\n",
    "hdfs dfs -rm -r data/ratings_median/\n",
    "hdfs dfs -rm -r data/ratings_std/\n",
    "hdfs dfs -rm -r data/user_with_most_ratings/\n",
    "\n",
    "\n",
    "echo \"\"\n",
    "echo \"-------------------------------------\"\n",
    "echo \"Starting MappReducer Program for HW4\"\n",
    "echo \"-------------------------------------\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"Finding Mean of ratings of each genre:\"\n",
    "echo \"\"\n",
    "\n",
    "sleep 2\n",
    "\n",
    "mapred streaming \\\n",
    "    -input data/movielens/ratings.csv \\\n",
    "    -output data/ratings_mean \\\n",
    "    -file ./mycodes/meanRatingMapper.py \\\n",
    "    -mapper meanRatingMapper.py \\\n",
    "    -file ./mycodes/meanRatingReducer.py \\\n",
    "    -reducer meanRatingReducer.py \\\n",
    "    -file ./movielens/movies.csv\n",
    "\n",
    "hdfs dfs -ls data/ratings_mean/\n",
    "echo \"\"\n",
    "echo \" Mean of ratings of each genre:\"\n",
    "echo \"\"\n",
    "hdfs dfs -cat data/ratings_mean/part-00000\n",
    "\n",
    "echo \"Copy result to local directory\"\n",
    "hdfs dfs -get data/ratings_mean/part-00000 ./ratings_mean.txt\n",
    "\n",
    "\n",
    "echo \"\"\n",
    "echo \"Finding Median of ratings of each genre..\"\n",
    "echo \"\"\n",
    "\n",
    "sleep 2\n",
    "\n",
    "mapred streaming \\\n",
    "    -input data/movielens/ratings.csv \\\n",
    "    -output data/ratings_median \\\n",
    "    -file ./mycodes/medianRatingMapper.py \\\n",
    "    -mapper medianRatingMapper.py \\\n",
    "    -file ./mycodes/medianRatingReducer.py \\\n",
    "    -reducer medianRatingReducer.py \\\n",
    "    -file ./movielens/movies.csv\n",
    "\n",
    "\n",
    "hdfs dfs -ls data/ratings_median/\n",
    "\n",
    "echo \"\"\n",
    "echo \" Median of ratings of each genre:\"\n",
    "echo \"\"\n",
    "hdfs dfs -cat data/ratings_median/part-00000\n",
    "\n",
    "echo \"Copy result to local directory\"\n",
    "hdfs dfs -get data/ratings_median/part-00000 ./ratings_median.txt\n",
    "\n",
    "\n",
    "\n",
    "echo \"\"\n",
    "echo \"Finding Standard deviation of ratings of each genre..\"\n",
    "echo \"\"\n",
    "\n",
    "sleep 2\n",
    "\n",
    "mapred streaming \\\n",
    "    -input data/movielens/ratings.csv \\\n",
    "    -output data/ratings_std \\\n",
    "    -file ./mycodes/stdRatingMapper.py \\\n",
    "    -mapper stdRatingMapper.py \\\n",
    "    -file ./mycodes/stdRatingReducer.py \\\n",
    "    -reducer stdRatingReducer.py \\\n",
    "    -file ./movielens/movies.csv\n",
    "\n",
    "\n",
    "hdfs dfs -ls data/ratings_std/\n",
    "\n",
    "echo \"\"\n",
    "echo \" Standard deviation of ratings of each genre:\"\n",
    "echo \"\"\n",
    "hdfs dfs -cat data/ratings_std/part-00000\n",
    "\n",
    "echo \"Copy result to local directory\"\n",
    "hdfs dfs -get data/ratings_std/part-00000 ./ratings_std.txt\n",
    "\n",
    "\n",
    "echo \"\"\n",
    "echo \"Finding  User who provides most rating and the genre this user watches most:\"\n",
    "echo \"\"\n",
    "\n",
    "sleep 2\n",
    "\n",
    "mapred streaming \\\n",
    "    -input data/movielens/ratings.csv \\\n",
    "    -output data/user_with_most_ratings \\\n",
    "    -file ./mycodes/userRatingMapper.py \\\n",
    "    -mapper userRatingMapper.py \\\n",
    "    -file ./mycodes/userRatingReducer.py \\\n",
    "    -reducer userRatingReducer.py \\\n",
    "    -file ./movielens/movies.csv\n",
    "\n",
    "hdfs dfs -ls data/user_with_most_ratings/\n",
    "\n",
    "echo \"\"\n",
    "echo \" User who provides most rating and the genre this user watches most:\"\n",
    "echo \"\"\n",
    "hdfs dfs -cat data/user_with_most_ratings/part-00000\n",
    "\n",
    "echo \"Copy result to local directory\"\n",
    "hdfs dfs -get data/user_with_most_ratings/part-00000 ./user_with_most_ratings.txt\n",
    "\n",
    "echo \"Program Completed\"\n",
    "./stop_hadoop.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.8 mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
